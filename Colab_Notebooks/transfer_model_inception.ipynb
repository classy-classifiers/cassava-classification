{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"transfer_model_cam.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"c489531d99da4758a761e2f7745571f9":{"model_module":"@jupyter-widgets/controls","model_name":"VBoxModel","state":{"_view_name":"VBoxView","_dom_classes":[],"_model_name":"VBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_67041074e9a746229248cf05f890a109","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_f7a4c390f98340f99abe0afd7a4ecb07","IPY_MODEL_ccd11a2256b141baa7454093779fb399"]}},"67041074e9a746229248cf05f890a109":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f7a4c390f98340f99abe0afd7a4ecb07":{"model_module":"@jupyter-widgets/controls","model_name":"LabelModel","state":{"_view_name":"LabelView","style":"IPY_MODEL_3cf67f3f07ff462b998ad6c1d72fce13","_dom_classes":[],"description":"","_model_name":"LabelModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 277.19MB of 277.19MB uploaded (0.00MB deduped)\r","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_464df94186f643068e5e155ad41e2149"}},"ccd11a2256b141baa7454093779fb399":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_6615ae6d182d4ec78fc3a994863f1c05","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_17b39463870f47cca8bd19618eb043f6"}},"3cf67f3f07ff462b998ad6c1d72fce13":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"464df94186f643068e5e155ad41e2149":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6615ae6d182d4ec78fc3a994863f1c05":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"17b39463870f47cca8bd19618eb043f6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LA13_4uQgD5M","executionInfo":{"status":"ok","timestamp":1616336371813,"user_tz":240,"elapsed":19801,"user":{"displayName":"Cameron Webster","photoUrl":"","userId":"11210168337344338301"}},"outputId":"93130a4b-6d7f-4009-e1ea-f3c2321ab4c4"},"source":["from google.colab import drive\n","drive.mount('/content/drive/')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive/\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"QC490JqQgu0y","executionInfo":{"status":"ok","timestamp":1616336371824,"user_tz":240,"elapsed":19792,"user":{"displayName":"Cameron Webster","photoUrl":"","userId":"11210168337344338301"}}},"source":["!mkdir .kaggle"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"7KgwnAXHgw4u","executionInfo":{"status":"ok","timestamp":1616336371827,"user_tz":240,"elapsed":19780,"user":{"displayName":"Cameron Webster","photoUrl":"","userId":"11210168337344338301"}}},"source":["import json\n","token = {\"username\":\"cameronwebster\",\"key\":\"5e70b65a76b1214dee43d83e7143f395\"}\n","with open('/content/.kaggle/kaggle.json', 'w') as file:\n","  json.dump(token, file)"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PLlfoRi8gy0D","executionInfo":{"status":"ok","timestamp":1616336445978,"user_tz":240,"elapsed":93921,"user":{"displayName":"Cameron Webster","photoUrl":"","userId":"11210168337344338301"}},"outputId":"f14b7e02-5206-48f3-bc40-3ff7800b7989"},"source":["!mkdir ~/.kaggle\n","!echo '{\"username\":\"cameronwebster\",\"key\":\"5e70b65a76b1214dee43d83e7143f395\"}' > ~/.kaggle/kaggle.json\n","!chmod 600 ~/.kaggle/kaggle.json && pip install kaggle\n","!pip install --upgrade --force-reinstall --no-deps kaggle\n","!rm -r cassava-leaf-disease-classification\n","!mkdir cassava-leaf-disease-classification\n","!kaggle competitions download -c cassava-leaf-disease-classification -p cassava-leaf-disease-classification"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: kaggle in /usr/local/lib/python3.7/dist-packages (1.5.10)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.23.0)\n","Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.15.0)\n","Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.8.1)\n","Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle) (4.0.1)\n","Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.24.3)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle) (2020.12.5)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle) (4.41.1)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (3.0.4)\n","Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle) (1.3)\n","Collecting kaggle\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3a/e7/3bac01547d2ed3d308ac92a0878fbdb0ed0f3d41fb1906c319ccbba1bfbc/kaggle-1.5.12.tar.gz (58kB)\n","\u001b[K     |████████████████████████████████| 61kB 4.0MB/s \n","\u001b[?25hBuilding wheels for collected packages: kaggle\n","  Building wheel for kaggle (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for kaggle: filename=kaggle-1.5.12-cp37-none-any.whl size=73053 sha256=c2309af12ccbf1bcfc9136f5a85b14ab203be435013c61f5852ba51b8051def9\n","  Stored in directory: /root/.cache/pip/wheels/a1/6a/26/d30b7499ff85a4a4593377a87ecf55f7d08af42f0de9b60303\n","Successfully built kaggle\n","Installing collected packages: kaggle\n","  Found existing installation: kaggle 1.5.10\n","    Uninstalling kaggle-1.5.10:\n","      Successfully uninstalled kaggle-1.5.10\n","Successfully installed kaggle-1.5.12\n","rm: cannot remove 'cassava-leaf-disease-classification': No such file or directory\n","Downloading cassava-leaf-disease-classification.zip to cassava-leaf-disease-classification\n","100% 5.75G/5.76G [01:06<00:00, 70.5MB/s]\n","100% 5.76G/5.76G [01:06<00:00, 92.8MB/s]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HnTiNd0mg1wJ","executionInfo":{"status":"ok","timestamp":1616336518079,"user_tz":240,"elapsed":166010,"user":{"displayName":"Cameron Webster","photoUrl":"","userId":"11210168337344338301"}},"outputId":"d5ed6efc-cef6-4c37-f315-fd710e065186"},"source":["from zipfile import ZipFile\n","file_name = '/content/cassava-leaf-disease-classification/cassava-leaf-disease-classification.zip'\n","\n","with ZipFile(file_name, 'r') as zip:\n","\n","  print(\"Extracting new files\")\n","  zip.extractall()\n","  print(\"done!\")"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Extracting new files\n","done!\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"3EOyGTCWjCIl","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1616336536933,"user_tz":240,"elapsed":184852,"user":{"displayName":"Cameron Webster","photoUrl":"","userId":"11210168337344338301"}},"outputId":"f337971f-33df-43c4-82f8-ffadaf4f6f0f"},"source":["import tensorflow as tf\n","import os\n","from functools import partial\n","!pip install -q wandb\n","import wandb\n","from matplotlib import pyplot as plt\n","\n","from tensorflow.keras.applications import InceptionV3\n","from tensorflow.keras.models import Sequential, Model\n","from tensorflow.keras.layers import (\n","    Dense, Dropout, Activation, Flatten, GlobalAveragePooling2D, InputLayer, \n","    Conv2D, MaxPooling2D, ZeroPadding2D, LeakyReLU, Dropout, BatchNormalization\n","    )\n","\n","from keras.layers.experimental.preprocessing import (\n","    RandomFlip, RandomRotation, RandomTranslation, RandomZoom, RandomContrast\n","    )\n","\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import (\n","    ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, LearningRateScheduler\n","    )\n","!pip install -q tensorflow_addons\n","from tensorflow_addons.optimizers import MultiOptimizer\n","from tensorflow.keras.optimizers.schedules import ExponentialDecay"],"execution_count":6,"outputs":[{"output_type":"stream","text":["\u001b[K     |████████████████████████████████| 2.0MB 8.1MB/s \n","\u001b[K     |████████████████████████████████| 133kB 38.8MB/s \n","\u001b[K     |████████████████████████████████| 102kB 10.1MB/s \n","\u001b[K     |████████████████████████████████| 163kB 38.7MB/s \n","\u001b[K     |████████████████████████████████| 71kB 7.0MB/s \n","\u001b[?25h  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[K     |████████████████████████████████| 706kB 7.8MB/s \n","\u001b[?25h"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"7RPT5MlfSRiv"},"source":["## Parameters, Logging Initiation"]},{"cell_type":"code","metadata":{"id":"UB_THSsyscRT","colab":{"base_uri":"https://localhost:8080/","height":614},"executionInfo":{"status":"ok","timestamp":1616336545233,"user_tz":240,"elapsed":193142,"user":{"displayName":"Cameron Webster","photoUrl":"","userId":"11210168337344338301"}},"outputId":"608e9f06-1a2d-4d5c-8b56-b4af5e424229"},"source":["AUTOTUNE = tf.data.experimental.AUTOTUNE\n","SHUFFLE_SEED = 42\n","BATCH_SIZE = 16 \n","# IMAGE_SIZE = [336, 336]\n","CROP_FACTOR = 0.7\n","IMAGE_SIZE = [int((520*CROP_FACTOR)-4)] * 2\n","EPOCHS = 100\n","LR = 0.001\n","CLASSES = 5\n","TRAIN_SPLIT = 0.8\n","\n","# Learning Rate\n","BASE_LR_INIT = 0.00001\n","HEAD_LR_INIT = 0.001\n","RAMPUP = 10\n","EXP_DECAY = 0.1\n","\n","# Early Stopping\n","MIN_DELTA_ES = 0.001\n","PATIENCE_ES = 15\n","\n","# Reduce LR on Plateau\n","FACTOR_RLR = 0.8\n","PATIENCE_RLR = 3\n","MIN_DELTA_RLR = 0.0001\n","MIN_LR = 0.0000001\n","\n","RECORD_PATH = tf.io.gfile.glob(\"train_tfrecords/*.tfrec\")\n","# SAVE_PATH = '/content/drive/Shareddrives/2040_Midterm_Project/Classy_Classifiers/model_checkpoints/inception_models/'\n","SAVE_PATH = '/content/drive/MyDrive/DATA_2040/'\n","SAVE_NAME = \"March20-v3-Inception-{epoch:02d}-{val_loss:.2f}.hdf5\"\n","\n","wandb.init(project=\"InceptionNet\")"],"execution_count":7,"outputs":[{"output_type":"display_data","data":{"application/javascript":["\n","        window._wandbApiKey = new Promise((resolve, reject) => {\n","            function loadScript(url) {\n","            return new Promise(function(resolve, reject) {\n","                let newScript = document.createElement(\"script\");\n","                newScript.onerror = reject;\n","                newScript.onload = resolve;\n","                document.body.appendChild(newScript);\n","                newScript.src = url;\n","            });\n","            }\n","            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n","            const iframe = document.createElement('iframe')\n","            iframe.style.cssText = \"width:0;height:0;border:none\"\n","            document.body.appendChild(iframe)\n","            const handshake = new Postmate({\n","                container: iframe,\n","                url: 'https://wandb.ai/authorize'\n","            });\n","            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n","            handshake.then(function(child) {\n","                child.on('authorize', data => {\n","                    clearTimeout(timeout)\n","                    resolve(data)\n","                });\n","            });\n","            })\n","        });\n","    "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"],"name":"stderr"},{"output_type":"display_data","data":{"text/html":["\n","                Tracking run with wandb version 0.10.22<br/>\n","                Syncing run <strong style=\"color:#cdcd00\">earthy-moon-11</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n","                Project page: <a href=\"https://wandb.ai/camweb/InceptionNet\" target=\"_blank\">https://wandb.ai/camweb/InceptionNet</a><br/>\n","                Run page: <a href=\"https://wandb.ai/camweb/InceptionNet/runs/11y45z2j\" target=\"_blank\">https://wandb.ai/camweb/InceptionNet/runs/11y45z2j</a><br/>\n","                Run data is saved locally in <code>/content/wandb/run-20210321_142222-11y45z2j</code><br/><br/>\n","            "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"execute_result","data":{"text/plain":["<wandb.sdk.wandb_run.Run at 0x7f2c6f0a1310>"],"text/html":["<h1>Run(11y45z2j)</h1><iframe src=\"https://wandb.ai/camweb/InceptionNet/runs/11y45z2j\" style=\"border:none;width:100%;height:400px\"></iframe>"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"bkN5X0blseCB","executionInfo":{"status":"ok","timestamp":1616336545234,"user_tz":240,"elapsed":193127,"user":{"displayName":"Cameron Webster","photoUrl":"","userId":"11210168337344338301"}}},"source":["def decode_image(image):\n","    image = tf.image.decode_jpeg(image, channels=3)\n","    image = tf.cast(image, tf.float32)\n","\n","    image = tf.image.central_crop(image, CROP_FACTOR)\n","\n","    image = image / 255.0 # recale by 255 for inputs between 0 and 1\n","\n","    return image"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"s0MNg_oosiBS","executionInfo":{"status":"ok","timestamp":1616336545235,"user_tz":240,"elapsed":193113,"user":{"displayName":"Cameron Webster","photoUrl":"","userId":"11210168337344338301"}}},"source":["def read_tfrecord(example, labeled):\n","    tfrecord_format = (\n","        {\n","            \"image\": tf.io.FixedLenFeature([], tf.string),\n","            \"target\": tf.io.FixedLenFeature([], tf.int64),\n","        }\n","        if labeled\n","        else {\"image\": tf.io.FixedLenFeature([], tf.string),}\n","    )\n","    example = tf.io.parse_single_example(example, tfrecord_format)\n","    image = decode_image(example[\"image\"])\n","    if labeled:\n","        label = tf.cast(example[\"target\"], tf.int32)\n","        label = tf.one_hot(label, 5)\n","        return image, label\n","    return image"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"0AMFT5L9sisx","executionInfo":{"status":"ok","timestamp":1616336545236,"user_tz":240,"elapsed":193088,"user":{"displayName":"Cameron Webster","photoUrl":"","userId":"11210168337344338301"}}},"source":["def load_dataset(filenames, labeled=True):\n","    ignore_order = tf.data.Options()\n","    ignore_order.experimental_deterministic = False  # disable order, increase speed\n","    dataset = tf.data.TFRecordDataset(\n","        filenames\n","    )  # automatically interleaves reads from multiple files\n","    dataset = dataset.with_options(\n","        ignore_order\n","    )  # uses data as soon as it streams in, rather than in its original order\n","    dataset = dataset.map(\n","        partial(read_tfrecord, labeled=labeled), num_parallel_calls=AUTOTUNE\n","    )\n","    # returns a dataset of (image, label) pairs if labeled=True or just images if labeled=False\n","    return dataset"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"XqqLCSdIsk6Y","executionInfo":{"status":"ok","timestamp":1616336548336,"user_tz":240,"elapsed":196172,"user":{"displayName":"Cameron Webster","photoUrl":"","userId":"11210168337344338301"}}},"source":["data_augmentation = Sequential([\n","    # RandomCrop(height=100, width=100),\n","    RandomFlip(\"horizontal_and_vertical\"),\n","    RandomRotation(15),\n","    RandomTranslation(height_factor=0.2, width_factor=0.2),\n","    # RandomZoom(height_factor=(-0.2,0.2), width_factor=(-0.2,0.2)),\n","    RandomContrast(factor=0.2)\n","])"],"execution_count":11,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-tgi8IJXSsht"},"source":["## Shuffling, Splitting, Batching, Augmenting train set, Caching val set, Prefetching\n","\n","splitting from: https://stackoverflow.com/questions/60704335/how-to-create-train-test-validation-split-of-tf-data-dataset-in-tf-2-1-0\n","\n","shuffling, batchingm caching, prefetching from https://www.kaggle.com/tt195361/splitting-tensorflow-dataset-for-validation"]},{"cell_type":"code","metadata":{"id":"_-T5N05CtyYk","executionInfo":{"status":"ok","timestamp":1616336548339,"user_tz":240,"elapsed":196164,"user":{"displayName":"Cameron Webster","photoUrl":"","userId":"11210168337344338301"}}},"source":["def get_datasets(filenames, labeled=True, train_split=TRAIN_SPLIT):\n","\n","    dataset = load_dataset(filenames, labeled=labeled)\n","    dataset = dataset.shuffle(2048, seed=SHUFFLE_SEED)\n","\n","    # First, split our train dataset into train and validation\n","\n","    # Size of dataset\n","    n = sum(1 for _ in dataset)\n","    n_train = int(n * train_split)\n","    n_valid = n - n_train\n","\n","    train_dataset = dataset.take(n_train)\n","    val_dataset = dataset.skip(n_train).take(n_valid)\n","\n","    train_dataset = train_dataset.batch(BATCH_SIZE)\n","    val_dataset = val_dataset.batch(BATCH_SIZE)\n","\n","    # Augment the training set\n","    train_dataset = train_dataset.map(lambda x, y: (data_augmentation(x), y), \n","                  num_parallel_calls=AUTOTUNE)\n","    \n","    # From Docs: \"The first time the dataset is iterated over, its elements \n","    # will be cached either in the specified file or in memory. Subsequent \n","    # iterations will use the cached data.\"\n","    val_dataset = val_dataset.cache()\n","    \n","    # prefetch \"allows later elements to be prepared while the current \n","    # element is being processed\"\n","    train_dataset = train_dataset.prefetch(buffer_size=AUTOTUNE)\n","    val_dataset = val_dataset.prefetch(buffer_size=AUTOTUNE)\n","\n","    return train_dataset, val_dataset"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"2FqgYIy_S1Xc","executionInfo":{"status":"ok","timestamp":1616336594054,"user_tz":240,"elapsed":241868,"user":{"displayName":"Cameron Webster","photoUrl":"","userId":"11210168337344338301"}}},"source":["train_dataset, val_dataset = get_datasets(RECORD_PATH)"],"execution_count":13,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UhFm_CD5S42T"},"source":["## (Optional) Inspect Records"]},{"cell_type":"code","metadata":{"id":"O9phyw5_S6Fb","executionInfo":{"status":"ok","timestamp":1616336594055,"user_tz":240,"elapsed":241859,"user":{"displayName":"Cameron Webster","photoUrl":"","userId":"11210168337344338301"}}},"source":["# image_batch, label_batch = next(iter(dataset_original))\n","\n","# def show_batch(image_batch, label_batch):\n","#     plt.figure(figsize=(10, 10))\n","#     for n in range(25):\n","#         ax = plt.subplot(5, 5, n + 1)\n","#         plt.imshow(image_batch[n] / 255.0)\n","#         plt.title(f\"{label_batch[n]}\")\n","#         plt.axis(\"off\")\n","\n","# show_batch(image_batch.numpy(), label_batch.numpy())\n","\n","# for raw_record in dataset_original.take(1):\n","    # example = tf.train.Example()\n","    # example.ParseFromString(raw_record)\n","    # print(example)"],"execution_count":14,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Hq2P7mYJ0K1N"},"source":["## Sequential Model"]},{"cell_type":"code","metadata":{"id":"hwRw-x8B2U39","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1616336598692,"user_tz":240,"elapsed":246484,"user":{"displayName":"Cameron Webster","photoUrl":"","userId":"11210168337344338301"}},"outputId":"82878ab9-cfa6-489f-d3db-574471591d76"},"source":["# Re-loads the MobileNet model without the top or FC layers\n","# tf.keras.backend.clear_session()\n","\n","inception_base = InceptionV3(include_top=False, \n","                            weights='imagenet', \n","                            input_shape=(IMAGE_SIZE[0],IMAGE_SIZE[1],3),\n","                            classes=CLASSES,\n","                            classifier_activation=None)\n","    \n","model = tf.keras.Sequential([\n","    InputLayer(input_shape=(IMAGE_SIZE[0],IMAGE_SIZE[1],3)),              \n","\n","    inception_base,\n","    GlobalAveragePooling2D(),\n","\n","    # Dense(1024, kernel_regularizer='l2'),\n","    # BatchNormalization(),\n","    # LeakyReLU(),\n","    # Dropout(0.5),\n","\n","    Dropout(0.5),\n","    Dense(512, kernel_regularizer='l2', activation='relu'),\n","    BatchNormalization(),\n","    \n","    # Dropout(0.5),\n","    # Dense(128, kernel_regularizer='l2', activation='relu'),\n","    # BatchNormalization(),\n","    \n","    # Dropout(0.5),\n","    # Dense(32, kernel_regularizer='l2', activation='relu'),\n","    # BatchNormalization(),\n","\n","    Dense(CLASSES,activation='softmax')\n","])\n","\n","inception_base.summary()"],"execution_count":15,"outputs":[{"output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n","87916544/87910968 [==============================] - 1s 0us/step\n","Model: \"inception_v3\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            [(None, 360, 360, 3) 0                                            \n","__________________________________________________________________________________________________\n","conv2d (Conv2D)                 (None, 179, 179, 32) 864         input_1[0][0]                    \n","__________________________________________________________________________________________________\n","batch_normalization (BatchNorma (None, 179, 179, 32) 96          conv2d[0][0]                     \n","__________________________________________________________________________________________________\n","activation (Activation)         (None, 179, 179, 32) 0           batch_normalization[0][0]        \n","__________________________________________________________________________________________________\n","conv2d_1 (Conv2D)               (None, 177, 177, 32) 9216        activation[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_1 (BatchNor (None, 177, 177, 32) 96          conv2d_1[0][0]                   \n","__________________________________________________________________________________________________\n","activation_1 (Activation)       (None, 177, 177, 32) 0           batch_normalization_1[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_2 (Conv2D)               (None, 177, 177, 64) 18432       activation_1[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_2 (BatchNor (None, 177, 177, 64) 192         conv2d_2[0][0]                   \n","__________________________________________________________________________________________________\n","activation_2 (Activation)       (None, 177, 177, 64) 0           batch_normalization_2[0][0]      \n","__________________________________________________________________________________________________\n","max_pooling2d (MaxPooling2D)    (None, 88, 88, 64)   0           activation_2[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_3 (Conv2D)               (None, 88, 88, 80)   5120        max_pooling2d[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_3 (BatchNor (None, 88, 88, 80)   240         conv2d_3[0][0]                   \n","__________________________________________________________________________________________________\n","activation_3 (Activation)       (None, 88, 88, 80)   0           batch_normalization_3[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_4 (Conv2D)               (None, 86, 86, 192)  138240      activation_3[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_4 (BatchNor (None, 86, 86, 192)  576         conv2d_4[0][0]                   \n","__________________________________________________________________________________________________\n","activation_4 (Activation)       (None, 86, 86, 192)  0           batch_normalization_4[0][0]      \n","__________________________________________________________________________________________________\n","max_pooling2d_1 (MaxPooling2D)  (None, 42, 42, 192)  0           activation_4[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_8 (Conv2D)               (None, 42, 42, 64)   12288       max_pooling2d_1[0][0]            \n","__________________________________________________________________________________________________\n","batch_normalization_8 (BatchNor (None, 42, 42, 64)   192         conv2d_8[0][0]                   \n","__________________________________________________________________________________________________\n","activation_8 (Activation)       (None, 42, 42, 64)   0           batch_normalization_8[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_6 (Conv2D)               (None, 42, 42, 48)   9216        max_pooling2d_1[0][0]            \n","__________________________________________________________________________________________________\n","conv2d_9 (Conv2D)               (None, 42, 42, 96)   55296       activation_8[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_6 (BatchNor (None, 42, 42, 48)   144         conv2d_6[0][0]                   \n","__________________________________________________________________________________________________\n","batch_normalization_9 (BatchNor (None, 42, 42, 96)   288         conv2d_9[0][0]                   \n","__________________________________________________________________________________________________\n","activation_6 (Activation)       (None, 42, 42, 48)   0           batch_normalization_6[0][0]      \n","__________________________________________________________________________________________________\n","activation_9 (Activation)       (None, 42, 42, 96)   0           batch_normalization_9[0][0]      \n","__________________________________________________________________________________________________\n","average_pooling2d (AveragePooli (None, 42, 42, 192)  0           max_pooling2d_1[0][0]            \n","__________________________________________________________________________________________________\n","conv2d_5 (Conv2D)               (None, 42, 42, 64)   12288       max_pooling2d_1[0][0]            \n","__________________________________________________________________________________________________\n","conv2d_7 (Conv2D)               (None, 42, 42, 64)   76800       activation_6[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_10 (Conv2D)              (None, 42, 42, 96)   82944       activation_9[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_11 (Conv2D)              (None, 42, 42, 32)   6144        average_pooling2d[0][0]          \n","__________________________________________________________________________________________________\n","batch_normalization_5 (BatchNor (None, 42, 42, 64)   192         conv2d_5[0][0]                   \n","__________________________________________________________________________________________________\n","batch_normalization_7 (BatchNor (None, 42, 42, 64)   192         conv2d_7[0][0]                   \n","__________________________________________________________________________________________________\n","batch_normalization_10 (BatchNo (None, 42, 42, 96)   288         conv2d_10[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_11 (BatchNo (None, 42, 42, 32)   96          conv2d_11[0][0]                  \n","__________________________________________________________________________________________________\n","activation_5 (Activation)       (None, 42, 42, 64)   0           batch_normalization_5[0][0]      \n","__________________________________________________________________________________________________\n","activation_7 (Activation)       (None, 42, 42, 64)   0           batch_normalization_7[0][0]      \n","__________________________________________________________________________________________________\n","activation_10 (Activation)      (None, 42, 42, 96)   0           batch_normalization_10[0][0]     \n","__________________________________________________________________________________________________\n","activation_11 (Activation)      (None, 42, 42, 32)   0           batch_normalization_11[0][0]     \n","__________________________________________________________________________________________________\n","mixed0 (Concatenate)            (None, 42, 42, 256)  0           activation_5[0][0]               \n","                                                                 activation_7[0][0]               \n","                                                                 activation_10[0][0]              \n","                                                                 activation_11[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_15 (Conv2D)              (None, 42, 42, 64)   16384       mixed0[0][0]                     \n","__________________________________________________________________________________________________\n","batch_normalization_15 (BatchNo (None, 42, 42, 64)   192         conv2d_15[0][0]                  \n","__________________________________________________________________________________________________\n","activation_15 (Activation)      (None, 42, 42, 64)   0           batch_normalization_15[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_13 (Conv2D)              (None, 42, 42, 48)   12288       mixed0[0][0]                     \n","__________________________________________________________________________________________________\n","conv2d_16 (Conv2D)              (None, 42, 42, 96)   55296       activation_15[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_13 (BatchNo (None, 42, 42, 48)   144         conv2d_13[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_16 (BatchNo (None, 42, 42, 96)   288         conv2d_16[0][0]                  \n","__________________________________________________________________________________________________\n","activation_13 (Activation)      (None, 42, 42, 48)   0           batch_normalization_13[0][0]     \n","__________________________________________________________________________________________________\n","activation_16 (Activation)      (None, 42, 42, 96)   0           batch_normalization_16[0][0]     \n","__________________________________________________________________________________________________\n","average_pooling2d_1 (AveragePoo (None, 42, 42, 256)  0           mixed0[0][0]                     \n","__________________________________________________________________________________________________\n","conv2d_12 (Conv2D)              (None, 42, 42, 64)   16384       mixed0[0][0]                     \n","__________________________________________________________________________________________________\n","conv2d_14 (Conv2D)              (None, 42, 42, 64)   76800       activation_13[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_17 (Conv2D)              (None, 42, 42, 96)   82944       activation_16[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_18 (Conv2D)              (None, 42, 42, 64)   16384       average_pooling2d_1[0][0]        \n","__________________________________________________________________________________________________\n","batch_normalization_12 (BatchNo (None, 42, 42, 64)   192         conv2d_12[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_14 (BatchNo (None, 42, 42, 64)   192         conv2d_14[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_17 (BatchNo (None, 42, 42, 96)   288         conv2d_17[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_18 (BatchNo (None, 42, 42, 64)   192         conv2d_18[0][0]                  \n","__________________________________________________________________________________________________\n","activation_12 (Activation)      (None, 42, 42, 64)   0           batch_normalization_12[0][0]     \n","__________________________________________________________________________________________________\n","activation_14 (Activation)      (None, 42, 42, 64)   0           batch_normalization_14[0][0]     \n","__________________________________________________________________________________________________\n","activation_17 (Activation)      (None, 42, 42, 96)   0           batch_normalization_17[0][0]     \n","__________________________________________________________________________________________________\n","activation_18 (Activation)      (None, 42, 42, 64)   0           batch_normalization_18[0][0]     \n","__________________________________________________________________________________________________\n","mixed1 (Concatenate)            (None, 42, 42, 288)  0           activation_12[0][0]              \n","                                                                 activation_14[0][0]              \n","                                                                 activation_17[0][0]              \n","                                                                 activation_18[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_22 (Conv2D)              (None, 42, 42, 64)   18432       mixed1[0][0]                     \n","__________________________________________________________________________________________________\n","batch_normalization_22 (BatchNo (None, 42, 42, 64)   192         conv2d_22[0][0]                  \n","__________________________________________________________________________________________________\n","activation_22 (Activation)      (None, 42, 42, 64)   0           batch_normalization_22[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_20 (Conv2D)              (None, 42, 42, 48)   13824       mixed1[0][0]                     \n","__________________________________________________________________________________________________\n","conv2d_23 (Conv2D)              (None, 42, 42, 96)   55296       activation_22[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_20 (BatchNo (None, 42, 42, 48)   144         conv2d_20[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_23 (BatchNo (None, 42, 42, 96)   288         conv2d_23[0][0]                  \n","__________________________________________________________________________________________________\n","activation_20 (Activation)      (None, 42, 42, 48)   0           batch_normalization_20[0][0]     \n","__________________________________________________________________________________________________\n","activation_23 (Activation)      (None, 42, 42, 96)   0           batch_normalization_23[0][0]     \n","__________________________________________________________________________________________________\n","average_pooling2d_2 (AveragePoo (None, 42, 42, 288)  0           mixed1[0][0]                     \n","__________________________________________________________________________________________________\n","conv2d_19 (Conv2D)              (None, 42, 42, 64)   18432       mixed1[0][0]                     \n","__________________________________________________________________________________________________\n","conv2d_21 (Conv2D)              (None, 42, 42, 64)   76800       activation_20[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_24 (Conv2D)              (None, 42, 42, 96)   82944       activation_23[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_25 (Conv2D)              (None, 42, 42, 64)   18432       average_pooling2d_2[0][0]        \n","__________________________________________________________________________________________________\n","batch_normalization_19 (BatchNo (None, 42, 42, 64)   192         conv2d_19[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_21 (BatchNo (None, 42, 42, 64)   192         conv2d_21[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_24 (BatchNo (None, 42, 42, 96)   288         conv2d_24[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_25 (BatchNo (None, 42, 42, 64)   192         conv2d_25[0][0]                  \n","__________________________________________________________________________________________________\n","activation_19 (Activation)      (None, 42, 42, 64)   0           batch_normalization_19[0][0]     \n","__________________________________________________________________________________________________\n","activation_21 (Activation)      (None, 42, 42, 64)   0           batch_normalization_21[0][0]     \n","__________________________________________________________________________________________________\n","activation_24 (Activation)      (None, 42, 42, 96)   0           batch_normalization_24[0][0]     \n","__________________________________________________________________________________________________\n","activation_25 (Activation)      (None, 42, 42, 64)   0           batch_normalization_25[0][0]     \n","__________________________________________________________________________________________________\n","mixed2 (Concatenate)            (None, 42, 42, 288)  0           activation_19[0][0]              \n","                                                                 activation_21[0][0]              \n","                                                                 activation_24[0][0]              \n","                                                                 activation_25[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_27 (Conv2D)              (None, 42, 42, 64)   18432       mixed2[0][0]                     \n","__________________________________________________________________________________________________\n","batch_normalization_27 (BatchNo (None, 42, 42, 64)   192         conv2d_27[0][0]                  \n","__________________________________________________________________________________________________\n","activation_27 (Activation)      (None, 42, 42, 64)   0           batch_normalization_27[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_28 (Conv2D)              (None, 42, 42, 96)   55296       activation_27[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_28 (BatchNo (None, 42, 42, 96)   288         conv2d_28[0][0]                  \n","__________________________________________________________________________________________________\n","activation_28 (Activation)      (None, 42, 42, 96)   0           batch_normalization_28[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_26 (Conv2D)              (None, 20, 20, 384)  995328      mixed2[0][0]                     \n","__________________________________________________________________________________________________\n","conv2d_29 (Conv2D)              (None, 20, 20, 96)   82944       activation_28[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_26 (BatchNo (None, 20, 20, 384)  1152        conv2d_26[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_29 (BatchNo (None, 20, 20, 96)   288         conv2d_29[0][0]                  \n","__________________________________________________________________________________________________\n","activation_26 (Activation)      (None, 20, 20, 384)  0           batch_normalization_26[0][0]     \n","__________________________________________________________________________________________________\n","activation_29 (Activation)      (None, 20, 20, 96)   0           batch_normalization_29[0][0]     \n","__________________________________________________________________________________________________\n","max_pooling2d_2 (MaxPooling2D)  (None, 20, 20, 288)  0           mixed2[0][0]                     \n","__________________________________________________________________________________________________\n","mixed3 (Concatenate)            (None, 20, 20, 768)  0           activation_26[0][0]              \n","                                                                 activation_29[0][0]              \n","                                                                 max_pooling2d_2[0][0]            \n","__________________________________________________________________________________________________\n","conv2d_34 (Conv2D)              (None, 20, 20, 128)  98304       mixed3[0][0]                     \n","__________________________________________________________________________________________________\n","batch_normalization_34 (BatchNo (None, 20, 20, 128)  384         conv2d_34[0][0]                  \n","__________________________________________________________________________________________________\n","activation_34 (Activation)      (None, 20, 20, 128)  0           batch_normalization_34[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_35 (Conv2D)              (None, 20, 20, 128)  114688      activation_34[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_35 (BatchNo (None, 20, 20, 128)  384         conv2d_35[0][0]                  \n","__________________________________________________________________________________________________\n","activation_35 (Activation)      (None, 20, 20, 128)  0           batch_normalization_35[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_31 (Conv2D)              (None, 20, 20, 128)  98304       mixed3[0][0]                     \n","__________________________________________________________________________________________________\n","conv2d_36 (Conv2D)              (None, 20, 20, 128)  114688      activation_35[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_31 (BatchNo (None, 20, 20, 128)  384         conv2d_31[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_36 (BatchNo (None, 20, 20, 128)  384         conv2d_36[0][0]                  \n","__________________________________________________________________________________________________\n","activation_31 (Activation)      (None, 20, 20, 128)  0           batch_normalization_31[0][0]     \n","__________________________________________________________________________________________________\n","activation_36 (Activation)      (None, 20, 20, 128)  0           batch_normalization_36[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_32 (Conv2D)              (None, 20, 20, 128)  114688      activation_31[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_37 (Conv2D)              (None, 20, 20, 128)  114688      activation_36[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_32 (BatchNo (None, 20, 20, 128)  384         conv2d_32[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_37 (BatchNo (None, 20, 20, 128)  384         conv2d_37[0][0]                  \n","__________________________________________________________________________________________________\n","activation_32 (Activation)      (None, 20, 20, 128)  0           batch_normalization_32[0][0]     \n","__________________________________________________________________________________________________\n","activation_37 (Activation)      (None, 20, 20, 128)  0           batch_normalization_37[0][0]     \n","__________________________________________________________________________________________________\n","average_pooling2d_3 (AveragePoo (None, 20, 20, 768)  0           mixed3[0][0]                     \n","__________________________________________________________________________________________________\n","conv2d_30 (Conv2D)              (None, 20, 20, 192)  147456      mixed3[0][0]                     \n","__________________________________________________________________________________________________\n","conv2d_33 (Conv2D)              (None, 20, 20, 192)  172032      activation_32[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_38 (Conv2D)              (None, 20, 20, 192)  172032      activation_37[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_39 (Conv2D)              (None, 20, 20, 192)  147456      average_pooling2d_3[0][0]        \n","__________________________________________________________________________________________________\n","batch_normalization_30 (BatchNo (None, 20, 20, 192)  576         conv2d_30[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_33 (BatchNo (None, 20, 20, 192)  576         conv2d_33[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_38 (BatchNo (None, 20, 20, 192)  576         conv2d_38[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_39 (BatchNo (None, 20, 20, 192)  576         conv2d_39[0][0]                  \n","__________________________________________________________________________________________________\n","activation_30 (Activation)      (None, 20, 20, 192)  0           batch_normalization_30[0][0]     \n","__________________________________________________________________________________________________\n","activation_33 (Activation)      (None, 20, 20, 192)  0           batch_normalization_33[0][0]     \n","__________________________________________________________________________________________________\n","activation_38 (Activation)      (None, 20, 20, 192)  0           batch_normalization_38[0][0]     \n","__________________________________________________________________________________________________\n","activation_39 (Activation)      (None, 20, 20, 192)  0           batch_normalization_39[0][0]     \n","__________________________________________________________________________________________________\n","mixed4 (Concatenate)            (None, 20, 20, 768)  0           activation_30[0][0]              \n","                                                                 activation_33[0][0]              \n","                                                                 activation_38[0][0]              \n","                                                                 activation_39[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_44 (Conv2D)              (None, 20, 20, 160)  122880      mixed4[0][0]                     \n","__________________________________________________________________________________________________\n","batch_normalization_44 (BatchNo (None, 20, 20, 160)  480         conv2d_44[0][0]                  \n","__________________________________________________________________________________________________\n","activation_44 (Activation)      (None, 20, 20, 160)  0           batch_normalization_44[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_45 (Conv2D)              (None, 20, 20, 160)  179200      activation_44[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_45 (BatchNo (None, 20, 20, 160)  480         conv2d_45[0][0]                  \n","__________________________________________________________________________________________________\n","activation_45 (Activation)      (None, 20, 20, 160)  0           batch_normalization_45[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_41 (Conv2D)              (None, 20, 20, 160)  122880      mixed4[0][0]                     \n","__________________________________________________________________________________________________\n","conv2d_46 (Conv2D)              (None, 20, 20, 160)  179200      activation_45[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_41 (BatchNo (None, 20, 20, 160)  480         conv2d_41[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_46 (BatchNo (None, 20, 20, 160)  480         conv2d_46[0][0]                  \n","__________________________________________________________________________________________________\n","activation_41 (Activation)      (None, 20, 20, 160)  0           batch_normalization_41[0][0]     \n","__________________________________________________________________________________________________\n","activation_46 (Activation)      (None, 20, 20, 160)  0           batch_normalization_46[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_42 (Conv2D)              (None, 20, 20, 160)  179200      activation_41[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_47 (Conv2D)              (None, 20, 20, 160)  179200      activation_46[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_42 (BatchNo (None, 20, 20, 160)  480         conv2d_42[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_47 (BatchNo (None, 20, 20, 160)  480         conv2d_47[0][0]                  \n","__________________________________________________________________________________________________\n","activation_42 (Activation)      (None, 20, 20, 160)  0           batch_normalization_42[0][0]     \n","__________________________________________________________________________________________________\n","activation_47 (Activation)      (None, 20, 20, 160)  0           batch_normalization_47[0][0]     \n","__________________________________________________________________________________________________\n","average_pooling2d_4 (AveragePoo (None, 20, 20, 768)  0           mixed4[0][0]                     \n","__________________________________________________________________________________________________\n","conv2d_40 (Conv2D)              (None, 20, 20, 192)  147456      mixed4[0][0]                     \n","__________________________________________________________________________________________________\n","conv2d_43 (Conv2D)              (None, 20, 20, 192)  215040      activation_42[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_48 (Conv2D)              (None, 20, 20, 192)  215040      activation_47[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_49 (Conv2D)              (None, 20, 20, 192)  147456      average_pooling2d_4[0][0]        \n","__________________________________________________________________________________________________\n","batch_normalization_40 (BatchNo (None, 20, 20, 192)  576         conv2d_40[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_43 (BatchNo (None, 20, 20, 192)  576         conv2d_43[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_48 (BatchNo (None, 20, 20, 192)  576         conv2d_48[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_49 (BatchNo (None, 20, 20, 192)  576         conv2d_49[0][0]                  \n","__________________________________________________________________________________________________\n","activation_40 (Activation)      (None, 20, 20, 192)  0           batch_normalization_40[0][0]     \n","__________________________________________________________________________________________________\n","activation_43 (Activation)      (None, 20, 20, 192)  0           batch_normalization_43[0][0]     \n","__________________________________________________________________________________________________\n","activation_48 (Activation)      (None, 20, 20, 192)  0           batch_normalization_48[0][0]     \n","__________________________________________________________________________________________________\n","activation_49 (Activation)      (None, 20, 20, 192)  0           batch_normalization_49[0][0]     \n","__________________________________________________________________________________________________\n","mixed5 (Concatenate)            (None, 20, 20, 768)  0           activation_40[0][0]              \n","                                                                 activation_43[0][0]              \n","                                                                 activation_48[0][0]              \n","                                                                 activation_49[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_54 (Conv2D)              (None, 20, 20, 160)  122880      mixed5[0][0]                     \n","__________________________________________________________________________________________________\n","batch_normalization_54 (BatchNo (None, 20, 20, 160)  480         conv2d_54[0][0]                  \n","__________________________________________________________________________________________________\n","activation_54 (Activation)      (None, 20, 20, 160)  0           batch_normalization_54[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_55 (Conv2D)              (None, 20, 20, 160)  179200      activation_54[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_55 (BatchNo (None, 20, 20, 160)  480         conv2d_55[0][0]                  \n","__________________________________________________________________________________________________\n","activation_55 (Activation)      (None, 20, 20, 160)  0           batch_normalization_55[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_51 (Conv2D)              (None, 20, 20, 160)  122880      mixed5[0][0]                     \n","__________________________________________________________________________________________________\n","conv2d_56 (Conv2D)              (None, 20, 20, 160)  179200      activation_55[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_51 (BatchNo (None, 20, 20, 160)  480         conv2d_51[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_56 (BatchNo (None, 20, 20, 160)  480         conv2d_56[0][0]                  \n","__________________________________________________________________________________________________\n","activation_51 (Activation)      (None, 20, 20, 160)  0           batch_normalization_51[0][0]     \n","__________________________________________________________________________________________________\n","activation_56 (Activation)      (None, 20, 20, 160)  0           batch_normalization_56[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_52 (Conv2D)              (None, 20, 20, 160)  179200      activation_51[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_57 (Conv2D)              (None, 20, 20, 160)  179200      activation_56[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_52 (BatchNo (None, 20, 20, 160)  480         conv2d_52[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_57 (BatchNo (None, 20, 20, 160)  480         conv2d_57[0][0]                  \n","__________________________________________________________________________________________________\n","activation_52 (Activation)      (None, 20, 20, 160)  0           batch_normalization_52[0][0]     \n","__________________________________________________________________________________________________\n","activation_57 (Activation)      (None, 20, 20, 160)  0           batch_normalization_57[0][0]     \n","__________________________________________________________________________________________________\n","average_pooling2d_5 (AveragePoo (None, 20, 20, 768)  0           mixed5[0][0]                     \n","__________________________________________________________________________________________________\n","conv2d_50 (Conv2D)              (None, 20, 20, 192)  147456      mixed5[0][0]                     \n","__________________________________________________________________________________________________\n","conv2d_53 (Conv2D)              (None, 20, 20, 192)  215040      activation_52[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_58 (Conv2D)              (None, 20, 20, 192)  215040      activation_57[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_59 (Conv2D)              (None, 20, 20, 192)  147456      average_pooling2d_5[0][0]        \n","__________________________________________________________________________________________________\n","batch_normalization_50 (BatchNo (None, 20, 20, 192)  576         conv2d_50[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_53 (BatchNo (None, 20, 20, 192)  576         conv2d_53[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_58 (BatchNo (None, 20, 20, 192)  576         conv2d_58[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_59 (BatchNo (None, 20, 20, 192)  576         conv2d_59[0][0]                  \n","__________________________________________________________________________________________________\n","activation_50 (Activation)      (None, 20, 20, 192)  0           batch_normalization_50[0][0]     \n","__________________________________________________________________________________________________\n","activation_53 (Activation)      (None, 20, 20, 192)  0           batch_normalization_53[0][0]     \n","__________________________________________________________________________________________________\n","activation_58 (Activation)      (None, 20, 20, 192)  0           batch_normalization_58[0][0]     \n","__________________________________________________________________________________________________\n","activation_59 (Activation)      (None, 20, 20, 192)  0           batch_normalization_59[0][0]     \n","__________________________________________________________________________________________________\n","mixed6 (Concatenate)            (None, 20, 20, 768)  0           activation_50[0][0]              \n","                                                                 activation_53[0][0]              \n","                                                                 activation_58[0][0]              \n","                                                                 activation_59[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_64 (Conv2D)              (None, 20, 20, 192)  147456      mixed6[0][0]                     \n","__________________________________________________________________________________________________\n","batch_normalization_64 (BatchNo (None, 20, 20, 192)  576         conv2d_64[0][0]                  \n","__________________________________________________________________________________________________\n","activation_64 (Activation)      (None, 20, 20, 192)  0           batch_normalization_64[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_65 (Conv2D)              (None, 20, 20, 192)  258048      activation_64[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_65 (BatchNo (None, 20, 20, 192)  576         conv2d_65[0][0]                  \n","__________________________________________________________________________________________________\n","activation_65 (Activation)      (None, 20, 20, 192)  0           batch_normalization_65[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_61 (Conv2D)              (None, 20, 20, 192)  147456      mixed6[0][0]                     \n","__________________________________________________________________________________________________\n","conv2d_66 (Conv2D)              (None, 20, 20, 192)  258048      activation_65[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_61 (BatchNo (None, 20, 20, 192)  576         conv2d_61[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_66 (BatchNo (None, 20, 20, 192)  576         conv2d_66[0][0]                  \n","__________________________________________________________________________________________________\n","activation_61 (Activation)      (None, 20, 20, 192)  0           batch_normalization_61[0][0]     \n","__________________________________________________________________________________________________\n","activation_66 (Activation)      (None, 20, 20, 192)  0           batch_normalization_66[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_62 (Conv2D)              (None, 20, 20, 192)  258048      activation_61[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_67 (Conv2D)              (None, 20, 20, 192)  258048      activation_66[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_62 (BatchNo (None, 20, 20, 192)  576         conv2d_62[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_67 (BatchNo (None, 20, 20, 192)  576         conv2d_67[0][0]                  \n","__________________________________________________________________________________________________\n","activation_62 (Activation)      (None, 20, 20, 192)  0           batch_normalization_62[0][0]     \n","__________________________________________________________________________________________________\n","activation_67 (Activation)      (None, 20, 20, 192)  0           batch_normalization_67[0][0]     \n","__________________________________________________________________________________________________\n","average_pooling2d_6 (AveragePoo (None, 20, 20, 768)  0           mixed6[0][0]                     \n","__________________________________________________________________________________________________\n","conv2d_60 (Conv2D)              (None, 20, 20, 192)  147456      mixed6[0][0]                     \n","__________________________________________________________________________________________________\n","conv2d_63 (Conv2D)              (None, 20, 20, 192)  258048      activation_62[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_68 (Conv2D)              (None, 20, 20, 192)  258048      activation_67[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_69 (Conv2D)              (None, 20, 20, 192)  147456      average_pooling2d_6[0][0]        \n","__________________________________________________________________________________________________\n","batch_normalization_60 (BatchNo (None, 20, 20, 192)  576         conv2d_60[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_63 (BatchNo (None, 20, 20, 192)  576         conv2d_63[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_68 (BatchNo (None, 20, 20, 192)  576         conv2d_68[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_69 (BatchNo (None, 20, 20, 192)  576         conv2d_69[0][0]                  \n","__________________________________________________________________________________________________\n","activation_60 (Activation)      (None, 20, 20, 192)  0           batch_normalization_60[0][0]     \n","__________________________________________________________________________________________________\n","activation_63 (Activation)      (None, 20, 20, 192)  0           batch_normalization_63[0][0]     \n","__________________________________________________________________________________________________\n","activation_68 (Activation)      (None, 20, 20, 192)  0           batch_normalization_68[0][0]     \n","__________________________________________________________________________________________________\n","activation_69 (Activation)      (None, 20, 20, 192)  0           batch_normalization_69[0][0]     \n","__________________________________________________________________________________________________\n","mixed7 (Concatenate)            (None, 20, 20, 768)  0           activation_60[0][0]              \n","                                                                 activation_63[0][0]              \n","                                                                 activation_68[0][0]              \n","                                                                 activation_69[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_72 (Conv2D)              (None, 20, 20, 192)  147456      mixed7[0][0]                     \n","__________________________________________________________________________________________________\n","batch_normalization_72 (BatchNo (None, 20, 20, 192)  576         conv2d_72[0][0]                  \n","__________________________________________________________________________________________________\n","activation_72 (Activation)      (None, 20, 20, 192)  0           batch_normalization_72[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_73 (Conv2D)              (None, 20, 20, 192)  258048      activation_72[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_73 (BatchNo (None, 20, 20, 192)  576         conv2d_73[0][0]                  \n","__________________________________________________________________________________________________\n","activation_73 (Activation)      (None, 20, 20, 192)  0           batch_normalization_73[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_70 (Conv2D)              (None, 20, 20, 192)  147456      mixed7[0][0]                     \n","__________________________________________________________________________________________________\n","conv2d_74 (Conv2D)              (None, 20, 20, 192)  258048      activation_73[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_70 (BatchNo (None, 20, 20, 192)  576         conv2d_70[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_74 (BatchNo (None, 20, 20, 192)  576         conv2d_74[0][0]                  \n","__________________________________________________________________________________________________\n","activation_70 (Activation)      (None, 20, 20, 192)  0           batch_normalization_70[0][0]     \n","__________________________________________________________________________________________________\n","activation_74 (Activation)      (None, 20, 20, 192)  0           batch_normalization_74[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_71 (Conv2D)              (None, 9, 9, 320)    552960      activation_70[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_75 (Conv2D)              (None, 9, 9, 192)    331776      activation_74[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_71 (BatchNo (None, 9, 9, 320)    960         conv2d_71[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_75 (BatchNo (None, 9, 9, 192)    576         conv2d_75[0][0]                  \n","__________________________________________________________________________________________________\n","activation_71 (Activation)      (None, 9, 9, 320)    0           batch_normalization_71[0][0]     \n","__________________________________________________________________________________________________\n","activation_75 (Activation)      (None, 9, 9, 192)    0           batch_normalization_75[0][0]     \n","__________________________________________________________________________________________________\n","max_pooling2d_3 (MaxPooling2D)  (None, 9, 9, 768)    0           mixed7[0][0]                     \n","__________________________________________________________________________________________________\n","mixed8 (Concatenate)            (None, 9, 9, 1280)   0           activation_71[0][0]              \n","                                                                 activation_75[0][0]              \n","                                                                 max_pooling2d_3[0][0]            \n","__________________________________________________________________________________________________\n","conv2d_80 (Conv2D)              (None, 9, 9, 448)    573440      mixed8[0][0]                     \n","__________________________________________________________________________________________________\n","batch_normalization_80 (BatchNo (None, 9, 9, 448)    1344        conv2d_80[0][0]                  \n","__________________________________________________________________________________________________\n","activation_80 (Activation)      (None, 9, 9, 448)    0           batch_normalization_80[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_77 (Conv2D)              (None, 9, 9, 384)    491520      mixed8[0][0]                     \n","__________________________________________________________________________________________________\n","conv2d_81 (Conv2D)              (None, 9, 9, 384)    1548288     activation_80[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_77 (BatchNo (None, 9, 9, 384)    1152        conv2d_77[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_81 (BatchNo (None, 9, 9, 384)    1152        conv2d_81[0][0]                  \n","__________________________________________________________________________________________________\n","activation_77 (Activation)      (None, 9, 9, 384)    0           batch_normalization_77[0][0]     \n","__________________________________________________________________________________________________\n","activation_81 (Activation)      (None, 9, 9, 384)    0           batch_normalization_81[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_78 (Conv2D)              (None, 9, 9, 384)    442368      activation_77[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_79 (Conv2D)              (None, 9, 9, 384)    442368      activation_77[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_82 (Conv2D)              (None, 9, 9, 384)    442368      activation_81[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_83 (Conv2D)              (None, 9, 9, 384)    442368      activation_81[0][0]              \n","__________________________________________________________________________________________________\n","average_pooling2d_7 (AveragePoo (None, 9, 9, 1280)   0           mixed8[0][0]                     \n","__________________________________________________________________________________________________\n","conv2d_76 (Conv2D)              (None, 9, 9, 320)    409600      mixed8[0][0]                     \n","__________________________________________________________________________________________________\n","batch_normalization_78 (BatchNo (None, 9, 9, 384)    1152        conv2d_78[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_79 (BatchNo (None, 9, 9, 384)    1152        conv2d_79[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_82 (BatchNo (None, 9, 9, 384)    1152        conv2d_82[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_83 (BatchNo (None, 9, 9, 384)    1152        conv2d_83[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_84 (Conv2D)              (None, 9, 9, 192)    245760      average_pooling2d_7[0][0]        \n","__________________________________________________________________________________________________\n","batch_normalization_76 (BatchNo (None, 9, 9, 320)    960         conv2d_76[0][0]                  \n","__________________________________________________________________________________________________\n","activation_78 (Activation)      (None, 9, 9, 384)    0           batch_normalization_78[0][0]     \n","__________________________________________________________________________________________________\n","activation_79 (Activation)      (None, 9, 9, 384)    0           batch_normalization_79[0][0]     \n","__________________________________________________________________________________________________\n","activation_82 (Activation)      (None, 9, 9, 384)    0           batch_normalization_82[0][0]     \n","__________________________________________________________________________________________________\n","activation_83 (Activation)      (None, 9, 9, 384)    0           batch_normalization_83[0][0]     \n","__________________________________________________________________________________________________\n","batch_normalization_84 (BatchNo (None, 9, 9, 192)    576         conv2d_84[0][0]                  \n","__________________________________________________________________________________________________\n","activation_76 (Activation)      (None, 9, 9, 320)    0           batch_normalization_76[0][0]     \n","__________________________________________________________________________________________________\n","mixed9_0 (Concatenate)          (None, 9, 9, 768)    0           activation_78[0][0]              \n","                                                                 activation_79[0][0]              \n","__________________________________________________________________________________________________\n","concatenate (Concatenate)       (None, 9, 9, 768)    0           activation_82[0][0]              \n","                                                                 activation_83[0][0]              \n","__________________________________________________________________________________________________\n","activation_84 (Activation)      (None, 9, 9, 192)    0           batch_normalization_84[0][0]     \n","__________________________________________________________________________________________________\n","mixed9 (Concatenate)            (None, 9, 9, 2048)   0           activation_76[0][0]              \n","                                                                 mixed9_0[0][0]                   \n","                                                                 concatenate[0][0]                \n","                                                                 activation_84[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_89 (Conv2D)              (None, 9, 9, 448)    917504      mixed9[0][0]                     \n","__________________________________________________________________________________________________\n","batch_normalization_89 (BatchNo (None, 9, 9, 448)    1344        conv2d_89[0][0]                  \n","__________________________________________________________________________________________________\n","activation_89 (Activation)      (None, 9, 9, 448)    0           batch_normalization_89[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_86 (Conv2D)              (None, 9, 9, 384)    786432      mixed9[0][0]                     \n","__________________________________________________________________________________________________\n","conv2d_90 (Conv2D)              (None, 9, 9, 384)    1548288     activation_89[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_86 (BatchNo (None, 9, 9, 384)    1152        conv2d_86[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_90 (BatchNo (None, 9, 9, 384)    1152        conv2d_90[0][0]                  \n","__________________________________________________________________________________________________\n","activation_86 (Activation)      (None, 9, 9, 384)    0           batch_normalization_86[0][0]     \n","__________________________________________________________________________________________________\n","activation_90 (Activation)      (None, 9, 9, 384)    0           batch_normalization_90[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_87 (Conv2D)              (None, 9, 9, 384)    442368      activation_86[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_88 (Conv2D)              (None, 9, 9, 384)    442368      activation_86[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_91 (Conv2D)              (None, 9, 9, 384)    442368      activation_90[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_92 (Conv2D)              (None, 9, 9, 384)    442368      activation_90[0][0]              \n","__________________________________________________________________________________________________\n","average_pooling2d_8 (AveragePoo (None, 9, 9, 2048)   0           mixed9[0][0]                     \n","__________________________________________________________________________________________________\n","conv2d_85 (Conv2D)              (None, 9, 9, 320)    655360      mixed9[0][0]                     \n","__________________________________________________________________________________________________\n","batch_normalization_87 (BatchNo (None, 9, 9, 384)    1152        conv2d_87[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_88 (BatchNo (None, 9, 9, 384)    1152        conv2d_88[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_91 (BatchNo (None, 9, 9, 384)    1152        conv2d_91[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_92 (BatchNo (None, 9, 9, 384)    1152        conv2d_92[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_93 (Conv2D)              (None, 9, 9, 192)    393216      average_pooling2d_8[0][0]        \n","__________________________________________________________________________________________________\n","batch_normalization_85 (BatchNo (None, 9, 9, 320)    960         conv2d_85[0][0]                  \n","__________________________________________________________________________________________________\n","activation_87 (Activation)      (None, 9, 9, 384)    0           batch_normalization_87[0][0]     \n","__________________________________________________________________________________________________\n","activation_88 (Activation)      (None, 9, 9, 384)    0           batch_normalization_88[0][0]     \n","__________________________________________________________________________________________________\n","activation_91 (Activation)      (None, 9, 9, 384)    0           batch_normalization_91[0][0]     \n","__________________________________________________________________________________________________\n","activation_92 (Activation)      (None, 9, 9, 384)    0           batch_normalization_92[0][0]     \n","__________________________________________________________________________________________________\n","batch_normalization_93 (BatchNo (None, 9, 9, 192)    576         conv2d_93[0][0]                  \n","__________________________________________________________________________________________________\n","activation_85 (Activation)      (None, 9, 9, 320)    0           batch_normalization_85[0][0]     \n","__________________________________________________________________________________________________\n","mixed9_1 (Concatenate)          (None, 9, 9, 768)    0           activation_87[0][0]              \n","                                                                 activation_88[0][0]              \n","__________________________________________________________________________________________________\n","concatenate_1 (Concatenate)     (None, 9, 9, 768)    0           activation_91[0][0]              \n","                                                                 activation_92[0][0]              \n","__________________________________________________________________________________________________\n","activation_93 (Activation)      (None, 9, 9, 192)    0           batch_normalization_93[0][0]     \n","__________________________________________________________________________________________________\n","mixed10 (Concatenate)           (None, 9, 9, 2048)   0           activation_85[0][0]              \n","                                                                 mixed9_1[0][0]                   \n","                                                                 concatenate_1[0][0]              \n","                                                                 activation_93[0][0]              \n","==================================================================================================\n","Total params: 21,802,784\n","Trainable params: 21,768,352\n","Non-trainable params: 34,432\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8mvsHqwr5ggH","executionInfo":{"status":"ok","timestamp":1616336598695,"user_tz":240,"elapsed":246472,"user":{"displayName":"Cameron Webster","photoUrl":"","userId":"11210168337344338301"}},"outputId":"4689342a-713c-4fc8-9db5-aa8bba755893"},"source":["checkpoint = ModelCheckpoint(SAVE_PATH+SAVE_NAME,\n","                             monitor = \"val_loss\",\n","                             mode = \"min\",\n","                             save_best_only = True,\n","                             save_weights_only = False,\n","                             verbose = 1)\n","\n","# class CheckpointNoOpt(tf.keras.callbacks.Callback):\n","\n","#     def on_epoch_end(self, epoch, logs=None):\n","#         model.save(filepath=SAVE_PATH + NAME_BASE + f\"-{epoch}-.hdf5\", \n","#                    overwrite=False, \n","#                    include_optimizer=False\n","# )\n","# checkpoint = CheckpointNoOpt()\n","\n","earlystop = EarlyStopping(monitor = 'val_loss', \n","                          min_delta = MIN_DELTA_ES, \n","                          patience = PATIENCE_ES,\n","                          verbose = 1,\n","                          restore_best_weights = True)\n","\n","reduce_lr = ReduceLROnPlateau(monitor = 'val_loss',\n","                              factor = FACTOR_RLR,\n","                              patience = PATIENCE_RLR,\n","                              verbose = 1,\n","                              min_delta = MIN_DELTA_RLR,\n","                              min_lr = MIN_LR)\n","\n","# def lr(epoch, start_lr, rampup_epochs, exp_decay):\n","#   if epoch < rampup_epochs:\n","#     return start_lr\n","#   else:\n","#     return start_lr * math.exp(-exp_decay * epoch)\n","\n","# def schedule_base(epoch):\n","#   return lr(epoch, BASE_LR_INIT, RAMPUP, EXP_DECAY)\n","\n","# def schedule_head(epoch):\n","#   return lr(epoch, HEAD_LR_INIT, RAMPUP, EXP_DECAY)\n","\n","# scheduler_base = LearningRateScheduler(schedule_base, verbose=0)\n","# scheduler_head = LearningRateScheduler(schedule_head, verbose=0)\n","\n","# scheduler_base = ExponentialDecay(initial_learning_rate=BASE_LR_INIT, \n","#                                   decay_steps=20, decay_rate=.1)\n","# scheduler_head = ExponentialDecay(initial_learning_rate=HEAD_LR_INIT, \n","#                                   decay_steps=20, decay_rate=.1)\n","\n","# var_list_base = model.layers[0]\n","# var_list_head = model.layers[1:]\n","# opt_base = Adam(learning_rate=scheduler_base)\n","# opt_head = Adam(learning_rate=scheduler_head)\n","\n","# optimizers_and_layers = [(opt_base, var_list_base),(opt_head, var_list_head)]\n","# opt = MultiOptimizer(optimizers_and_layers)\n","\n","\n","model.compile(loss = 'categorical_crossentropy',\n","              # optimizer = opt,\n","              optimizer = Adam(learning_rate=LR),\n","              metrics = ['accuracy'])\n","\n","callbacks = [checkpoint,earlystop, reduce_lr, wandb.keras.WandbCallback()]\n","# callbacks = [checkpoint, earlystop, wandb.keras.WandbCallback()]\n","\n","model.build(input_shape=(BATCH_SIZE,IMAGE_SIZE[0],IMAGE_SIZE[1],3))\n","model.summary()"],"execution_count":16,"outputs":[{"output_type":"stream","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","inception_v3 (Functional)    (None, 9, 9, 2048)        21802784  \n","_________________________________________________________________\n","global_average_pooling2d (Gl (None, 2048)              0         \n","_________________________________________________________________\n","dropout (Dropout)            (None, 2048)              0         \n","_________________________________________________________________\n","dense (Dense)                (None, 512)               1049088   \n","_________________________________________________________________\n","batch_normalization_94 (Batc (None, 512)               2048      \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 5)                 2565      \n","=================================================================\n","Total params: 22,856,485\n","Trainable params: 22,821,029\n","Non-trainable params: 35,456\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"CRyN3PyYAF6q","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"error","timestamp":1616359907116,"user_tz":240,"elapsed":23554869,"user":{"displayName":"Cameron Webster","photoUrl":"","userId":"11210168337344338301"}},"outputId":"bd1c29f0-f238-4539-c009-de159c244354"},"source":["history = model.fit(\n","    train_dataset,\n","    # class_weight = class_weights,\n","    epochs = EPOCHS,\n","    validation_data = val_dataset,\n","    callbacks = callbacks,\n","    verbose = 1#,\n","    #batch_size=BATCH_SIZE#,\n","    #steps_per_epoch = STEPS_PER_EPOCH,\n","    #validation_steps = VALIDATION_STEPS\n",")"],"execution_count":17,"outputs":[{"output_type":"stream","text":["Epoch 1/100\n","1070/1070 [==============================] - 349s 300ms/step - loss: 4.5196 - accuracy: 0.5716 - val_loss: 1.8509 - val_accuracy: 0.3481\n","\n","Epoch 00001: val_loss improved from inf to 1.85092, saving model to /content/drive/MyDrive/DATA_2040/March20-v3-Inception-01-1.85.hdf5\n","Epoch 2/100\n","1070/1070 [==============================] - 286s 262ms/step - loss: 1.2679 - accuracy: 0.6103 - val_loss: 1.0339 - val_accuracy: 0.6584\n","\n","Epoch 00002: val_loss improved from 1.85092 to 1.03390, saving model to /content/drive/MyDrive/DATA_2040/March20-v3-Inception-02-1.03.hdf5\n","Epoch 3/100\n","1070/1070 [==============================] - 282s 258ms/step - loss: 1.0882 - accuracy: 0.6414 - val_loss: 1.0210 - val_accuracy: 0.6645\n","\n","Epoch 00003: val_loss improved from 1.03390 to 1.02102, saving model to /content/drive/MyDrive/DATA_2040/March20-v3-Inception-03-1.02.hdf5\n","Epoch 4/100\n","1070/1070 [==============================] - 283s 259ms/step - loss: 0.9799 - accuracy: 0.6674 - val_loss: 1.2497 - val_accuracy: 0.6220\n","\n","Epoch 00004: val_loss did not improve from 1.02102\n","Epoch 5/100\n","1070/1070 [==============================] - 278s 255ms/step - loss: 0.9226 - accuracy: 0.6824 - val_loss: 1.0591 - val_accuracy: 0.6572\n","\n","Epoch 00005: val_loss did not improve from 1.02102\n","Epoch 6/100\n","1070/1070 [==============================] - 279s 257ms/step - loss: 0.8623 - accuracy: 0.7038 - val_loss: 2.8849 - val_accuracy: 0.7112\n","\n","Epoch 00006: val_loss did not improve from 1.02102\n","\n","Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.000800000037997961.\n","Epoch 7/100\n","1070/1070 [==============================] - 278s 256ms/step - loss: 0.8042 - accuracy: 0.7328 - val_loss: 0.8436 - val_accuracy: 0.7355\n","\n","Epoch 00007: val_loss improved from 1.02102 to 0.84357, saving model to /content/drive/MyDrive/DATA_2040/March20-v3-Inception-07-0.84.hdf5\n","Epoch 8/100\n","1070/1070 [==============================] - 283s 259ms/step - loss: 0.7614 - accuracy: 0.7479 - val_loss: 1.1209 - val_accuracy: 0.5846\n","\n","Epoch 00008: val_loss did not improve from 0.84357\n","Epoch 9/100\n","1070/1070 [==============================] - 279s 256ms/step - loss: 0.7327 - accuracy: 0.7656 - val_loss: 0.7635 - val_accuracy: 0.7421\n","\n","Epoch 00009: val_loss improved from 0.84357 to 0.76353, saving model to /content/drive/MyDrive/DATA_2040/March20-v3-Inception-09-0.76.hdf5\n","Epoch 10/100\n","1070/1070 [==============================] - 283s 259ms/step - loss: 0.7009 - accuracy: 0.7658 - val_loss: 0.9174 - val_accuracy: 0.6734\n","\n","Epoch 00010: val_loss did not improve from 0.76353\n","Epoch 11/100\n","1070/1070 [==============================] - 277s 255ms/step - loss: 0.6785 - accuracy: 0.7755 - val_loss: 0.8200 - val_accuracy: 0.7325\n","\n","Epoch 00011: val_loss did not improve from 0.76353\n","Epoch 12/100\n","1070/1070 [==============================] - 275s 253ms/step - loss: 0.6695 - accuracy: 0.7760 - val_loss: 0.6599 - val_accuracy: 0.7907\n","\n","Epoch 00012: val_loss improved from 0.76353 to 0.65988, saving model to /content/drive/MyDrive/DATA_2040/March20-v3-Inception-12-0.66.hdf5\n","Epoch 13/100\n","1070/1070 [==============================] - 276s 253ms/step - loss: 0.6637 - accuracy: 0.7793 - val_loss: 0.6423 - val_accuracy: 0.7890\n","\n","Epoch 00013: val_loss improved from 0.65988 to 0.64234, saving model to /content/drive/MyDrive/DATA_2040/March20-v3-Inception-13-0.64.hdf5\n","Epoch 14/100\n","1070/1070 [==============================] - 275s 252ms/step - loss: 0.6269 - accuracy: 0.7917 - val_loss: 0.5708 - val_accuracy: 0.8126\n","\n","Epoch 00014: val_loss improved from 0.64234 to 0.57079, saving model to /content/drive/MyDrive/DATA_2040/March20-v3-Inception-14-0.57.hdf5\n","Epoch 15/100\n","1070/1070 [==============================] - 279s 255ms/step - loss: 0.6386 - accuracy: 0.7924 - val_loss: 0.6498 - val_accuracy: 0.7815\n","\n","Epoch 00015: val_loss did not improve from 0.57079\n","Epoch 16/100\n","1070/1070 [==============================] - 276s 254ms/step - loss: 0.6357 - accuracy: 0.7881 - val_loss: 0.5883 - val_accuracy: 0.8065\n","\n","Epoch 00016: val_loss did not improve from 0.57079\n","Epoch 17/100\n","1070/1070 [==============================] - 278s 256ms/step - loss: 0.6082 - accuracy: 0.7967 - val_loss: 0.5656 - val_accuracy: 0.8126\n","\n","Epoch 00017: val_loss improved from 0.57079 to 0.56557, saving model to /content/drive/MyDrive/DATA_2040/March20-v3-Inception-17-0.57.hdf5\n","Epoch 18/100\n","1070/1070 [==============================] - 280s 256ms/step - loss: 0.6060 - accuracy: 0.7955 - val_loss: 0.7682 - val_accuracy: 0.7304\n","\n","Epoch 00018: val_loss did not improve from 0.56557\n","Epoch 19/100\n","1070/1070 [==============================] - 275s 253ms/step - loss: 0.5808 - accuracy: 0.8068 - val_loss: 0.5992 - val_accuracy: 0.8051\n","\n","Epoch 00019: val_loss did not improve from 0.56557\n","Epoch 20/100\n","1070/1070 [==============================] - 273s 251ms/step - loss: 0.5878 - accuracy: 0.8083 - val_loss: 0.7052 - val_accuracy: 0.7572\n","\n","Epoch 00020: val_loss did not improve from 0.56557\n","\n","Epoch 00020: ReduceLROnPlateau reducing learning rate to 0.0006400000303983689.\n","Epoch 21/100\n","1070/1070 [==============================] - 271s 249ms/step - loss: 0.5600 - accuracy: 0.8134 - val_loss: 0.5219 - val_accuracy: 0.8287\n","\n","Epoch 00021: val_loss improved from 0.56557 to 0.52187, saving model to /content/drive/MyDrive/DATA_2040/March20-v3-Inception-21-0.52.hdf5\n","Epoch 22/100\n","1070/1070 [==============================] - 273s 249ms/step - loss: 0.5380 - accuracy: 0.8196 - val_loss: 0.5049 - val_accuracy: 0.8336\n","\n","Epoch 00022: val_loss improved from 0.52187 to 0.50489, saving model to /content/drive/MyDrive/DATA_2040/March20-v3-Inception-22-0.50.hdf5\n","Epoch 23/100\n","1070/1070 [==============================] - 272s 248ms/step - loss: 0.5531 - accuracy: 0.8176 - val_loss: 0.8845 - val_accuracy: 0.6827\n","\n","Epoch 00023: val_loss did not improve from 0.50489\n","Epoch 24/100\n","1070/1070 [==============================] - 274s 252ms/step - loss: 0.5472 - accuracy: 0.8210 - val_loss: 0.8297 - val_accuracy: 0.7213\n","\n","Epoch 00024: val_loss did not improve from 0.50489\n","Epoch 25/100\n","1070/1070 [==============================] - 273s 251ms/step - loss: 0.5313 - accuracy: 0.8257 - val_loss: 0.5581 - val_accuracy: 0.8171\n","\n","Epoch 00025: val_loss did not improve from 0.50489\n","\n","Epoch 00025: ReduceLROnPlateau reducing learning rate to 0.0005120000336319208.\n","Epoch 26/100\n","1070/1070 [==============================] - 273s 251ms/step - loss: 0.5144 - accuracy: 0.8309 - val_loss: 0.5248 - val_accuracy: 0.8220\n","\n","Epoch 00026: val_loss did not improve from 0.50489\n","Epoch 27/100\n","1070/1070 [==============================] - 277s 255ms/step - loss: 0.5172 - accuracy: 0.8236 - val_loss: 0.4798 - val_accuracy: 0.8414\n","\n","Epoch 00027: val_loss improved from 0.50489 to 0.47977, saving model to /content/drive/MyDrive/DATA_2040/March20-v3-Inception-27-0.48.hdf5\n","Epoch 28/100\n","1070/1070 [==============================] - 284s 260ms/step - loss: 0.5127 - accuracy: 0.8281 - val_loss: 0.4766 - val_accuracy: 0.8416\n","\n","Epoch 00028: val_loss improved from 0.47977 to 0.47660, saving model to /content/drive/MyDrive/DATA_2040/March20-v3-Inception-28-0.48.hdf5\n","Epoch 29/100\n","1070/1070 [==============================] - 289s 264ms/step - loss: 0.5163 - accuracy: 0.8331 - val_loss: 0.5076 - val_accuracy: 0.8343\n","\n","Epoch 00029: val_loss did not improve from 0.47660\n","Epoch 30/100\n","1070/1070 [==============================] - 286s 263ms/step - loss: 0.5039 - accuracy: 0.8344 - val_loss: 0.5982 - val_accuracy: 0.7886\n","\n","Epoch 00030: val_loss did not improve from 0.47660\n","Epoch 31/100\n","1070/1070 [==============================] - 287s 264ms/step - loss: 0.4885 - accuracy: 0.8406 - val_loss: 0.5935 - val_accuracy: 0.7949\n","\n","Epoch 00031: val_loss did not improve from 0.47660\n","\n","Epoch 00031: ReduceLROnPlateau reducing learning rate to 0.00040960004553198815.\n","Epoch 32/100\n","1070/1070 [==============================] - 286s 263ms/step - loss: 0.4797 - accuracy: 0.8405 - val_loss: 0.5045 - val_accuracy: 0.8311\n","\n","Epoch 00032: val_loss did not improve from 0.47660\n","Epoch 33/100\n","1070/1070 [==============================] - 286s 263ms/step - loss: 0.4761 - accuracy: 0.8434 - val_loss: 0.4883 - val_accuracy: 0.8346\n","\n","Epoch 00033: val_loss did not improve from 0.47660\n","Epoch 34/100\n","1070/1070 [==============================] - 283s 260ms/step - loss: 0.4921 - accuracy: 0.8394 - val_loss: 0.4886 - val_accuracy: 0.8339\n","\n","Epoch 00034: val_loss did not improve from 0.47660\n","\n","Epoch 00034: ReduceLROnPlateau reducing learning rate to 0.00032768002711236477.\n","Epoch 35/100\n","1070/1070 [==============================] - 284s 261ms/step - loss: 0.4648 - accuracy: 0.8489 - val_loss: 0.4627 - val_accuracy: 0.8481\n","\n","Epoch 00035: val_loss improved from 0.47660 to 0.46271, saving model to /content/drive/MyDrive/DATA_2040/March20-v3-Inception-35-0.46.hdf5\n","Epoch 36/100\n","1070/1070 [==============================] - 290s 265ms/step - loss: 0.4651 - accuracy: 0.8450 - val_loss: 0.4411 - val_accuracy: 0.8547\n","\n","Epoch 00036: val_loss improved from 0.46271 to 0.44111, saving model to /content/drive/MyDrive/DATA_2040/March20-v3-Inception-36-0.44.hdf5\n","Epoch 37/100\n","1070/1070 [==============================] - 288s 263ms/step - loss: 0.4596 - accuracy: 0.8456 - val_loss: 0.4307 - val_accuracy: 0.8551\n","\n","Epoch 00037: val_loss improved from 0.44111 to 0.43067, saving model to /content/drive/MyDrive/DATA_2040/March20-v3-Inception-37-0.43.hdf5\n","Epoch 38/100\n","1070/1070 [==============================] - 287s 263ms/step - loss: 0.4531 - accuracy: 0.8461 - val_loss: 0.4562 - val_accuracy: 0.8507\n","\n","Epoch 00038: val_loss did not improve from 0.43067\n","Epoch 39/100\n","1070/1070 [==============================] - 286s 263ms/step - loss: 0.4565 - accuracy: 0.8476 - val_loss: 0.4213 - val_accuracy: 0.8654\n","\n","Epoch 00039: val_loss improved from 0.43067 to 0.42130, saving model to /content/drive/MyDrive/DATA_2040/March20-v3-Inception-39-0.42.hdf5\n","Epoch 40/100\n","1070/1070 [==============================] - 290s 265ms/step - loss: 0.4581 - accuracy: 0.8427 - val_loss: 0.5059 - val_accuracy: 0.8364\n","\n","Epoch 00040: val_loss did not improve from 0.42130\n","Epoch 41/100\n","1070/1070 [==============================] - 287s 264ms/step - loss: 0.4513 - accuracy: 0.8504 - val_loss: 0.4499 - val_accuracy: 0.8563\n","\n","Epoch 00041: val_loss did not improve from 0.42130\n","Epoch 42/100\n","1070/1070 [==============================] - 287s 263ms/step - loss: 0.4504 - accuracy: 0.8495 - val_loss: 0.4057 - val_accuracy: 0.8640\n","\n","Epoch 00042: val_loss improved from 0.42130 to 0.40575, saving model to /content/drive/MyDrive/DATA_2040/March20-v3-Inception-42-0.41.hdf5\n","Epoch 43/100\n","1070/1070 [==============================] - 290s 266ms/step - loss: 0.4440 - accuracy: 0.8505 - val_loss: 0.4222 - val_accuracy: 0.8586\n","\n","Epoch 00043: val_loss did not improve from 0.40575\n","Epoch 44/100\n","1070/1070 [==============================] - 284s 261ms/step - loss: 0.4405 - accuracy: 0.8573 - val_loss: 0.4370 - val_accuracy: 0.8572\n","\n","Epoch 00044: val_loss did not improve from 0.40575\n","Epoch 45/100\n","1070/1070 [==============================] - 284s 261ms/step - loss: 0.4453 - accuracy: 0.8549 - val_loss: 0.5310 - val_accuracy: 0.8241\n","\n","Epoch 00045: val_loss did not improve from 0.40575\n","\n","Epoch 00045: ReduceLROnPlateau reducing learning rate to 0.0002621440216898918.\n","Epoch 46/100\n","1070/1070 [==============================] - 284s 261ms/step - loss: 0.4374 - accuracy: 0.8552 - val_loss: 0.4210 - val_accuracy: 0.8554\n","\n","Epoch 00046: val_loss did not improve from 0.40575\n","Epoch 47/100\n","1070/1070 [==============================] - 284s 261ms/step - loss: 0.4310 - accuracy: 0.8581 - val_loss: 0.4214 - val_accuracy: 0.8673\n","\n","Epoch 00047: val_loss did not improve from 0.40575\n","Epoch 48/100\n","1070/1070 [==============================] - 285s 262ms/step - loss: 0.4236 - accuracy: 0.8617 - val_loss: 0.4337 - val_accuracy: 0.8584\n","\n","Epoch 00048: val_loss did not improve from 0.40575\n","\n","Epoch 00048: ReduceLROnPlateau reducing learning rate to 0.00020971521735191345.\n","Epoch 49/100\n","1070/1070 [==============================] - 283s 260ms/step - loss: 0.4185 - accuracy: 0.8648 - val_loss: 0.4377 - val_accuracy: 0.8484\n","\n","Epoch 00049: val_loss did not improve from 0.40575\n","Epoch 50/100\n","1070/1070 [==============================] - 283s 260ms/step - loss: 0.4154 - accuracy: 0.8595 - val_loss: 0.3959 - val_accuracy: 0.8701\n","\n","Epoch 00050: val_loss improved from 0.40575 to 0.39588, saving model to /content/drive/MyDrive/DATA_2040/March20-v3-Inception-50-0.40.hdf5\n","Epoch 51/100\n","1070/1070 [==============================] - 283s 259ms/step - loss: 0.4250 - accuracy: 0.8575 - val_loss: 0.3923 - val_accuracy: 0.8694\n","\n","Epoch 00051: val_loss improved from 0.39588 to 0.39230, saving model to /content/drive/MyDrive/DATA_2040/March20-v3-Inception-51-0.39.hdf5\n","Epoch 52/100\n","1070/1070 [==============================] - 280s 257ms/step - loss: 0.4120 - accuracy: 0.8645 - val_loss: 0.4007 - val_accuracy: 0.8673\n","\n","Epoch 00052: val_loss did not improve from 0.39230\n","Epoch 53/100\n","1070/1070 [==============================] - 275s 253ms/step - loss: 0.4225 - accuracy: 0.8568 - val_loss: 0.4303 - val_accuracy: 0.8591\n","\n","Epoch 00053: val_loss did not improve from 0.39230\n","Epoch 54/100\n","1070/1070 [==============================] - 274s 252ms/step - loss: 0.4151 - accuracy: 0.8616 - val_loss: 0.4375 - val_accuracy: 0.8495\n","\n","Epoch 00054: val_loss did not improve from 0.39230\n","\n","Epoch 00054: ReduceLROnPlateau reducing learning rate to 0.00016777217388153076.\n","Epoch 55/100\n","1070/1070 [==============================] - 274s 252ms/step - loss: 0.4040 - accuracy: 0.8647 - val_loss: 0.4055 - val_accuracy: 0.8617\n","\n","Epoch 00055: val_loss did not improve from 0.39230\n","Epoch 56/100\n","1070/1070 [==============================] - 277s 255ms/step - loss: 0.4013 - accuracy: 0.8639 - val_loss: 0.4229 - val_accuracy: 0.8579\n","\n","Epoch 00056: val_loss did not improve from 0.39230\n","Epoch 57/100\n","1070/1070 [==============================] - 278s 256ms/step - loss: 0.4038 - accuracy: 0.8662 - val_loss: 0.3883 - val_accuracy: 0.8694\n","\n","Epoch 00057: val_loss improved from 0.39230 to 0.38834, saving model to /content/drive/MyDrive/DATA_2040/March20-v3-Inception-57-0.39.hdf5\n","Epoch 58/100\n","1070/1070 [==============================] - 279s 255ms/step - loss: 0.4033 - accuracy: 0.8688 - val_loss: 0.3792 - val_accuracy: 0.8783\n","\n","Epoch 00058: val_loss improved from 0.38834 to 0.37916, saving model to /content/drive/MyDrive/DATA_2040/March20-v3-Inception-58-0.38.hdf5\n","Epoch 59/100\n","1070/1070 [==============================] - 283s 259ms/step - loss: 0.3994 - accuracy: 0.8680 - val_loss: 0.4041 - val_accuracy: 0.8631\n","\n","Epoch 00059: val_loss did not improve from 0.37916\n","Epoch 60/100\n","1070/1070 [==============================] - 279s 256ms/step - loss: 0.3938 - accuracy: 0.8695 - val_loss: 0.4367 - val_accuracy: 0.8556\n","\n","Epoch 00060: val_loss did not improve from 0.37916\n","Epoch 61/100\n","1070/1070 [==============================] - 279s 256ms/step - loss: 0.3929 - accuracy: 0.8694 - val_loss: 0.3903 - val_accuracy: 0.8699\n","\n","Epoch 00061: val_loss did not improve from 0.37916\n","\n","Epoch 00061: ReduceLROnPlateau reducing learning rate to 0.00013421773910522462.\n","Epoch 62/100\n","1070/1070 [==============================] - 275s 252ms/step - loss: 0.3902 - accuracy: 0.8713 - val_loss: 0.3921 - val_accuracy: 0.8694\n","\n","Epoch 00062: val_loss did not improve from 0.37916\n","Epoch 63/100\n","1070/1070 [==============================] - 270s 248ms/step - loss: 0.3917 - accuracy: 0.8695 - val_loss: 0.3932 - val_accuracy: 0.8675\n","\n","Epoch 00063: val_loss did not improve from 0.37916\n","Epoch 64/100\n","1070/1070 [==============================] - 270s 248ms/step - loss: 0.3854 - accuracy: 0.8716 - val_loss: 0.3787 - val_accuracy: 0.8736\n","\n","Epoch 00064: val_loss improved from 0.37916 to 0.37874, saving model to /content/drive/MyDrive/DATA_2040/March20-v3-Inception-64-0.38.hdf5\n","Epoch 65/100\n","1070/1070 [==============================] - 282s 258ms/step - loss: 0.3785 - accuracy: 0.8723 - val_loss: 0.4069 - val_accuracy: 0.8638\n","\n","Epoch 00065: val_loss did not improve from 0.37874\n","Epoch 66/100\n","1070/1070 [==============================] - 279s 256ms/step - loss: 0.3835 - accuracy: 0.8732 - val_loss: 0.4063 - val_accuracy: 0.8621\n","\n","Epoch 00066: val_loss did not improve from 0.37874\n","Epoch 67/100\n","1070/1070 [==============================] - 279s 256ms/step - loss: 0.3798 - accuracy: 0.8717 - val_loss: 0.3824 - val_accuracy: 0.8727\n","\n","Epoch 00067: val_loss did not improve from 0.37874\n","\n","Epoch 00067: ReduceLROnPlateau reducing learning rate to 0.00010737419361248613.\n","Epoch 68/100\n","1070/1070 [==============================] - 280s 257ms/step - loss: 0.3678 - accuracy: 0.8773 - val_loss: 0.3908 - val_accuracy: 0.8673\n","\n","Epoch 00068: val_loss did not improve from 0.37874\n","Epoch 69/100\n","1070/1070 [==============================] - 278s 256ms/step - loss: 0.3631 - accuracy: 0.8830 - val_loss: 0.3739 - val_accuracy: 0.8708\n","\n","Epoch 00069: val_loss improved from 0.37874 to 0.37394, saving model to /content/drive/MyDrive/DATA_2040/March20-v3-Inception-69-0.37.hdf5\n","Epoch 70/100\n","1070/1070 [==============================] - 283s 259ms/step - loss: 0.3816 - accuracy: 0.8729 - val_loss: 0.3831 - val_accuracy: 0.8699\n","\n","Epoch 00070: val_loss did not improve from 0.37394\n","Epoch 71/100\n","1070/1070 [==============================] - 281s 259ms/step - loss: 0.3717 - accuracy: 0.8792 - val_loss: 0.3910 - val_accuracy: 0.8671\n","\n","Epoch 00071: val_loss did not improve from 0.37394\n","Epoch 72/100\n","1070/1070 [==============================] - 283s 260ms/step - loss: 0.3764 - accuracy: 0.8712 - val_loss: 0.3934 - val_accuracy: 0.8685\n","\n","Epoch 00072: val_loss did not improve from 0.37394\n","\n","Epoch 00072: ReduceLROnPlateau reducing learning rate to 8.589935605414213e-05.\n","Epoch 73/100\n","1070/1070 [==============================] - 283s 260ms/step - loss: 0.3747 - accuracy: 0.8745 - val_loss: 0.3730 - val_accuracy: 0.8766\n","\n","Epoch 00073: val_loss improved from 0.37394 to 0.37296, saving model to /content/drive/MyDrive/DATA_2040/March20-v3-Inception-73-0.37.hdf5\n","Epoch 74/100\n","1070/1070 [==============================] - 287s 262ms/step - loss: 0.3750 - accuracy: 0.8736 - val_loss: 0.3675 - val_accuracy: 0.8762\n","\n","Epoch 00074: val_loss improved from 0.37296 to 0.36747, saving model to /content/drive/MyDrive/DATA_2040/March20-v3-Inception-74-0.37.hdf5\n","Epoch 75/100\n","1070/1070 [==============================] - 287s 262ms/step - loss: 0.3665 - accuracy: 0.8775 - val_loss: 0.3825 - val_accuracy: 0.8666\n","\n","Epoch 00075: val_loss did not improve from 0.36747\n","Epoch 76/100\n","1070/1070 [==============================] - 284s 261ms/step - loss: 0.3716 - accuracy: 0.8760 - val_loss: 0.3799 - val_accuracy: 0.8671\n","\n","Epoch 00076: val_loss did not improve from 0.36747\n","Epoch 77/100\n","1070/1070 [==============================] - 283s 260ms/step - loss: 0.3759 - accuracy: 0.8744 - val_loss: 0.3826 - val_accuracy: 0.8678\n","\n","Epoch 00077: val_loss did not improve from 0.36747\n","\n","Epoch 00077: ReduceLROnPlateau reducing learning rate to 6.871948717162013e-05.\n","Epoch 78/100\n","1070/1070 [==============================] - 282s 259ms/step - loss: 0.3534 - accuracy: 0.8800 - val_loss: 0.3722 - val_accuracy: 0.8734\n","\n","Epoch 00078: val_loss did not improve from 0.36747\n","Epoch 79/100\n","1070/1070 [==============================] - 282s 259ms/step - loss: 0.3563 - accuracy: 0.8809 - val_loss: 0.3737 - val_accuracy: 0.8689\n","\n","Epoch 00079: val_loss did not improve from 0.36747\n","Epoch 80/100\n","1070/1070 [==============================] - 282s 259ms/step - loss: 0.3497 - accuracy: 0.8804 - val_loss: 0.3690 - val_accuracy: 0.8745\n","\n","Epoch 00080: val_loss did not improve from 0.36747\n","\n","Epoch 00080: ReduceLROnPlateau reducing learning rate to 5.497558740898967e-05.\n","Epoch 81/100\n","1070/1070 [==============================] - 281s 259ms/step - loss: 0.3574 - accuracy: 0.8810 - val_loss: 0.3698 - val_accuracy: 0.8752\n","\n","Epoch 00081: val_loss did not improve from 0.36747\n","Epoch 82/100\n","1070/1070 [==============================] - 280s 257ms/step - loss: 0.3568 - accuracy: 0.8817 - val_loss: 0.3633 - val_accuracy: 0.8773\n","\n","Epoch 00082: val_loss improved from 0.36747 to 0.36333, saving model to /content/drive/MyDrive/DATA_2040/March20-v3-Inception-82-0.36.hdf5\n","Epoch 83/100\n"," 429/1070 [===========>..................] - ETA: 2:43 - loss: 0.3764 - accuracy: 0.8694"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-17-54ea0a10cda4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;31m#,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;31m#batch_size=BATCH_SIZE#,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m#steps_per_epoch = STEPS_PER_EPOCH,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/wandb/integration/keras/keras.py\u001b[0m in \u001b[0;36mnew_v2\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mcbk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcbks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m                 \u001b[0mset_wandb_attrs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcbk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mold_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[0mtraining_arrays\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morig_fit_loop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mold_arrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"5uGWq9tGFVu7","colab":{"base_uri":"https://localhost:8080/","height":232},"executionInfo":{"status":"error","timestamp":1616359921721,"user_tz":240,"elapsed":339,"user":{"displayName":"Cameron Webster","photoUrl":"","userId":"11210168337344338301"}},"outputId":"a0d53b55-b79a-449b-e41e-72fcc2090837"},"source":["plt.plot(history.history['accuracy'])\n","plt.plot(history.history['val_accuracy'])\n","plt.title('model accuracy')\n","plt.ylabel('accuracy')\n","plt.xlabel('epoch')\n","plt.legend(['train', 'val'], loc='upper left')\n","plt.show()\n","\n","plt.plot(history.history['loss'])\n","plt.plot(history.history['val_loss'])\n","plt.title('model loss')\n","plt.ylabel('loss')\n","plt.xlabel('epoch')\n","plt.legend(['train', 'val'], loc='upper left')\n","plt.show()"],"execution_count":19,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-19-e44e76881c55>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'epoch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":709,"referenced_widgets":["c489531d99da4758a761e2f7745571f9","67041074e9a746229248cf05f890a109","f7a4c390f98340f99abe0afd7a4ecb07","ccd11a2256b141baa7454093779fb399","3cf67f3f07ff462b998ad6c1d72fce13","464df94186f643068e5e155ad41e2149","6615ae6d182d4ec78fc3a994863f1c05","17b39463870f47cca8bd19618eb043f6"]},"id":"aAUC5-Wq64z8","executionInfo":{"status":"ok","timestamp":1616359916674,"user_tz":240,"elapsed":4791,"user":{"displayName":"Cameron Webster","photoUrl":"","userId":"11210168337344338301"}},"outputId":"f7d01a37-c0d4-4c22-f562-e63c1a482410"},"source":["wandb.finish()"],"execution_count":18,"outputs":[{"output_type":"display_data","data":{"text/html":["<br/>Waiting for W&B process to finish, PID 362<br/>Program ended successfully."],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c489531d99da4758a761e2f7745571f9","version_minor":0,"version_major":2},"text/plain":["VBox(children=(Label(value=' 262.30MB of 262.30MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=…"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["Find user logs for this run at: <code>/content/wandb/run-20210321_142222-11y45z2j/logs/debug.log</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["Find internal logs for this run at: <code>/content/wandb/run-20210321_142222-11y45z2j/logs/debug-internal.log</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["<h3>Run summary:</h3><br/><style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n","    </style><table class=\"wandb\">\n","<tr><td>epoch</td><td>81</td></tr><tr><td>loss</td><td>0.34634</td></tr><tr><td>accuracy</td><td>0.88532</td></tr><tr><td>val_loss</td><td>0.36333</td></tr><tr><td>val_accuracy</td><td>0.87734</td></tr><tr><td>lr</td><td>5e-05</td></tr><tr><td>_runtime</td><td>23246</td></tr><tr><td>_timestamp</td><td>1616359788</td></tr><tr><td>_step</td><td>81</td></tr><tr><td>best_val_loss</td><td>0.36333</td></tr><tr><td>best_epoch</td><td>81</td></tr></table>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["<h3>Run history:</h3><br/><style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n","    </style><table class=\"wandb\">\n","<tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>loss</td><td>█▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>accuracy</td><td>▁▂▃▄▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇███████████████</td></tr><tr><td>val_loss</td><td>█▄▄▃▃▃▂▂▂▂▂▃▂▂▂▂▂▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▅▅▆▆▆▇▇▇▇▇▅▇█▇▇▇██▇████████████████████</td></tr><tr><td>lr</td><td>███▇▇▇▇▇▇▇▅▅▅▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁</td></tr><tr><td>_runtime</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>_timestamp</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr></table><br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["\n","                    <br/>Synced <strong style=\"color:#cdcd00\">earthy-moon-11</strong>: <a href=\"https://wandb.ai/camweb/InceptionNet/runs/11y45z2j\" target=\"_blank\">https://wandb.ai/camweb/InceptionNet/runs/11y45z2j</a><br/>\n","                "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"OHUPVjkgoEnu","executionInfo":{"status":"aborted","timestamp":1616359906342,"user_tz":240,"elapsed":23554022,"user":{"displayName":"Cameron Webster","photoUrl":"","userId":"11210168337344338301"}}},"source":["model.evaluate(val_dataset)"],"execution_count":null,"outputs":[]}]}