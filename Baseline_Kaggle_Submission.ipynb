{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Baseline_Kaggle_Submission.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPDVljDYSS7q+q2CYP1RGtP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/classy-classifiers/cassava-classification/blob/main/Baseline_Kaggle_Submission.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TSBdJBoA68cu"
      },
      "source": [
        "## *Code copied from our Kaggle submission notebook - the paths here will not work outside of the Kaggle environment*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3q173-dO6ebD"
      },
      "source": [
        "# import the requisite packages\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import preprocessing"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LcuZWye26jin"
      },
      "source": [
        "# credentials\n",
        "FILEPATH = '../input/cassava-leaf-disease-classification'\n",
        "RESULTSPATH = './'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZPReMwrH6pIn"
      },
      "source": [
        "# list of image file names\n",
        "train_imgs_dir = os.path.join(FILEPATH, 'train_images')\n",
        "img_names = os.listdir(train_imgs_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xrvS6NI26sXd"
      },
      "source": [
        "labels_df['label'].value_counts()\n",
        "#-----------------------------------------------------------------------------------------------------\n",
        "# def baseline_classifier_1(img): return 3\n",
        "# test_images = os.listdir(os.path.join(FILEPATH, 'test_images'))\n",
        "# predictions = []\n",
        "# for image in test_images:\n",
        "#     predictions.append(baseline_classifier_1(image))\n",
        "# sub = pd.DataFrame({'image_id': test_images, 'label': predictions})\n",
        "# sub.to_csv(os.path.join(RESULTSPATH, 'submission_baseline_1.csv'), index = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ezHeWfYp6xZU"
      },
      "source": [
        "# changing the labels to the class names because the data loader needs string\n",
        "labels_map_short = {0: 'CBB', 1: 'CBSD', 2: 'CGM', 3: 'CMD', 4: 'Healthy'}\n",
        "labels_df = labels_df.replace({\"label\": labels_map_short})\n",
        "labels_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YOZhcfif60Ek"
      },
      "source": [
        "base_train_datagen = preprocessing.image.ImageDataGenerator(validation_split = 0.2)\n",
        "base_train_gen = base_train_datagen.flow_from_dataframe(dataframe=labels_df,\n",
        "                                                        directory=train_imgs_dir,\n",
        "                                                        subset = 'training',\n",
        "                                                        x_col='image_id',\n",
        "                                                        y_col='label',\n",
        "                                                        target_size=(600, 800),\n",
        "                                                        batch_size=128,\n",
        "                                                        labels=list(labels_df['label']),\n",
        "                                                        class_mode='categorical')\n",
        "base_val_datagen = preprocessing.image.ImageDataGenerator(validation_split = 0.2)\n",
        "base_val_gen = base_val_datagen.flow_from_dataframe(dataframe=labels_df,\n",
        "                                                    directory=train_imgs_dir,\n",
        "                                                    subset='validation',\n",
        "                                                    x_col='image_id',\n",
        "                                                    y_col='label',\n",
        "                                                    target_size=(600, 800),\n",
        "                                                    batch_size=128,\n",
        "                                                    labels=list(labels_df['label']),\n",
        "                                                    class_mode='categorical')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fgDb_I7762GE"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from tensorflow.keras.layers import Conv2D, AvgPool2D\n",
        "from tensorflow.keras import callbacks\n",
        "from tensorflow import optimizers\n",
        "def baseline_net():\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(filters=6, \n",
        "                     kernel_size=5, \n",
        "                     activation='relu',\n",
        "                     padding='same', \n",
        "                     input_shape = [600, 800, 3]))\n",
        "    model.add(AvgPool2D(pool_size=2, strides=2))\n",
        "    model.add(Conv2D(filters=16,\n",
        "                     kernel_size=5,\n",
        "                     activation='relu'))\n",
        "    model.add(AvgPool2D(pool_size=2, strides=2))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(60, activation='relu'))\n",
        "    model.add(Dense(42, activation='relu'))\n",
        "    model.add(Dense(5, activation='softmax'))\n",
        "    return model\n",
        "baseline_cnn = baseline_net()\n",
        "baseline_cnn.summary()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQza3BwQ64P7"
      },
      "source": [
        "baseline_cnn.compile(optimizer = optimizers.Adam(lr = 0.001),\n",
        "                     loss = \"categorical_crossentropy\",\n",
        "                     metrics = [\"accuracy\"])\n",
        "early_stop = callbacks.EarlyStopping(monitor = 'val_loss', \n",
        "                                     min_delta = 0.001, \n",
        "                                     patience = 5, \n",
        "                                     mode = 'min', \n",
        "                                     verbose = 1,\n",
        "                                     restore_best_weights = True)\n",
        "base_history = baseline_cnn.fit(base_train_gen,\n",
        "                                epochs=10,\n",
        "                                callbacks=early_stop,\n",
        "                                verbose=1,\n",
        "                                validation_data=base_val_gen)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "07GtTGth66A_"
      },
      "source": [
        "plt.plot(base_history.history['accuracy'])\n",
        "plt.plot(base_history.history['val_accuracy'])\n",
        "plt.title('Base Model Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.grid()\n",
        "plt.savefig('base_cnn_acc.png', dpi=100)\n",
        "plt.show()\n",
        "plt.plot(base_history.history['loss'])\n",
        "plt.plot(base_history.history['val_loss'])\n",
        "plt.title('Base Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.grid()\n",
        "plt.savefig('base_cnn_loss.png', dpi=100)\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GuoTxaO967nk"
      },
      "source": [
        "test_path = '../input/cassava-leaf-disease-classification/test_images'\n",
        "test_images = os.listdir(test_path)\n",
        "predictions = []\n",
        "for image_id in test_images:\n",
        "    image = Image.open(os.path.join(test_path, image_id))\n",
        "    image = np.array(image)\n",
        "    predictions.append(np.argmax(baseline_cnn.predict(image)))\n",
        "sub = pd.DataFrame({'image_id': test_images, 'label': predictions})\n",
        "sub.to_csv(os.path.join(RESULTSPATH, 'submission.csv'), index = False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}